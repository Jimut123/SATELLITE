{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiResUNET_jimutmap.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVQwLZYntGXC",
        "outputId": "a2360d46-13f7-4d3b-ec36-a6793d8389b1"
      },
      "source": [
        "! gdown https://drive.google.com/u/3/uc?id=1-52ga1hIGY-_2cIaS-gRmWkt14BJOxO9"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/3/uc?id=1-52ga1hIGY-_2cIaS-gRmWkt14BJOxO9\n",
            "To: /content/jimutmap_less.zip\n",
            "926MB [00:04, 213MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAM_U4jeAl10"
      },
      "source": [
        "! unzip -qq jimutmap_less.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21M4J-QiAooT"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import glob\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufSLNlYGAyaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb023ad-ee71-4b13-adc0-2b9bd0b95941"
      },
      "source": [
        "import glob\n",
        "all_img_files = glob.glob('jimutmap_less/map/*')\n",
        "all_mask_files = glob.glob('jimutmap_less/roads/*')\n",
        "print(len(all_img_files))\n",
        "print(len(all_mask_files))\n",
        "print(all_img_files[:10])\n",
        "print(all_mask_files[:10])\n",
        "\n",
        "#img = cv2.imread('trainx/X_img_144.bmp', cv2.IMREAD_COLOR)\n",
        "#img.shape\n",
        "\n",
        "#plt.imshow(img[:,:,::-1])\n",
        "\n",
        "img_files = glob.glob('jimutmap_less/map/*')\n",
        "msk_files = glob.glob('jimutmap_less/roads/*')\n",
        "\n",
        "img_files.sort()\n",
        "msk_files.sort()\n",
        "\n",
        "print(len(img_files))\n",
        "print(len(msk_files))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61950\n",
            "61950\n",
            "['jimutmap_less/map/391023_227838.jpeg', 'jimutmap_less/map/390949_228416.jpeg', 'jimutmap_less/map/390973_228689.jpeg', 'jimutmap_less/map/390880_228449.jpeg', 'jimutmap_less/map/390902_228170.jpeg', 'jimutmap_less/map/390528_228252.jpeg', 'jimutmap_less/map/391084_228044.jpeg', 'jimutmap_less/map/390755_228437.jpeg', 'jimutmap_less/map/390341_228154.jpeg', 'jimutmap_less/map/390832_228582.jpeg']\n",
            "['jimutmap_less/roads/390828_227989_road.png', 'jimutmap_less/roads/390543_228473_road.png', 'jimutmap_less/roads/390978_228712_road.png', 'jimutmap_less/roads/391026_227735_road.png', 'jimutmap_less/roads/390784_228260_road.png', 'jimutmap_less/roads/390938_228582_road.png', 'jimutmap_less/roads/390584_228625_road.png', 'jimutmap_less/roads/391092_227809_road.png', 'jimutmap_less/roads/391004_227843_road.png', 'jimutmap_less/roads/391014_228032_road.png']\n",
            "61950\n",
            "61950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tckXFer_AyXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d42915f-f3f6-493b-a986-9d5a17fa7a4a"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for img_fl in tqdm(img_files):\n",
        "  #print(img_fl)\n",
        "  #break\n",
        "  img = cv2.imread('{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
        "  resized_img = cv2.resize(img,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "  #plt.imshow(resized_img)\n",
        "  #plt.show()\n",
        "  X.append(resized_img)\n",
        "  #print(img_fl)\n",
        "  mask_name = \"jimutmap_less/roads/\"+str(img_fl.split('.')[0]).split('/')[-1]+\"_road.png\"\n",
        "  #print(\"mn = \",mask_name)\n",
        "  #break\n",
        "  msk = cv2.imread('{}'.format(mask_name), cv2.IMREAD_GRAYSCALE)\n",
        "  resized_msk = cv2.resize(msk,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "  #plt.imshow(resized_msk)\n",
        "  Y.append(resized_msk)\n",
        "  #break\n",
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 46038/61950 [01:35<59:09,  4.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczJzf-UAyUc"
      },
      "source": [
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
        "\n",
        "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train = Y_train / 255\n",
        "Y_test = Y_test / 255\n",
        "\n",
        "Y_train = np.round(Y_train,0)\t\n",
        "Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr71QfvzAyRT"
      },
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "\n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "\n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def MultiResUnet(height, width, n_channels):\n",
        "    '''\n",
        "    MultiResUNet\n",
        "\n",
        "    Arguments:\n",
        "        height {int} -- height of image\n",
        "        width {int} -- width of image\n",
        "        n_channels {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RM5y6ngNSoj"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    fp = open('models/MultiResUNET_jimutmap.json','w')\n",
        "    fp.write(model_json)\n",
        "    model.save_weights('models/MultiResUNET_jimutmap.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V63gatMUNYJ1"
      },
      "source": [
        "jaccard_index_list = []\n",
        "dice_coeff_list = []\n",
        "\n",
        "def evaluateModel(model, X_test, Y_test, batchSize):\n",
        "\n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i])\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))\n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "\n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))\n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "\n",
        "\n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "\n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "\n",
        "    jaccard_index_list.append(jacard)\n",
        "    dice_coeff_list.append(dice)\n",
        "    fp = open('models/log.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('models/best.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('models/best.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        saveModel(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uMfatsXNaFj"
      },
      "source": [
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import json \n",
        "\n",
        "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
        "    epochs = 10\n",
        "    #for epoch in range(epochs):\n",
        "    #print('Epoch : {}'.format(epoch+1))\n",
        "    history = model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=epochs, verbose=1)\n",
        "\n",
        "    # convert the history.history dict to a pandas DataFrame:\n",
        "    hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "    \n",
        "\n",
        "    # save to json:\n",
        "    hist_json_file = 'history.json'\n",
        "    # with open(hist_json_file, 'a') as out:\n",
        "    #     out.write(hist_df.to_json())\n",
        "    #     out.write(\",\")\n",
        "    #     out.close()\n",
        "\n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "       hist_df.to_json(f)\n",
        "\n",
        "    # or save to csv:\n",
        "    hist_csv_file = 'history.csv'\n",
        "    # with open(hist_csv_file, 'a') as out:\n",
        "    #     out.write(str(hist_df.to_csv()))\n",
        "    #     out.write(\",\")\n",
        "    #     out.close()\n",
        "\n",
        "\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "\n",
        "    evaluateModel(model,X_test, Y_test,batchSize)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = MultiResUnet(height=256, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, Recall(), Precision() ,'accuracy'])\n",
        "\n",
        "saveModel(model)\n",
        "\n",
        "fp = open('models/log.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/best.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=150, batchSize=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9YKIm-INcCL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}