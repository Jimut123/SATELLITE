{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiResUNET_Zanzibar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT14WiGgq1Rv",
        "outputId": "cd274656-ae6e-4ff9-fc21-b43aa2ef380c"
      },
      "source": [
        "! gdown https://drive.google.com/u/3/uc?id=1--qv7im7ND4OMJamMZy2WY43Kw4-7SjX"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/3/uc?id=1--qv7im7ND4OMJamMZy2WY43Kw4-7SjX\n",
            "To: /content/znz-classify.zip\n",
            "495MB [00:02, 165MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKmPJQU58wEZ"
      },
      "source": [
        "! unzip -qq znz-classify.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cBG92ni83-o"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77SCwB19Dw9",
        "outputId": "349d42f9-4351-48e2-f9b2-2fb4dbe193a6"
      },
      "source": [
        "import glob\n",
        "all_img_files = glob.glob('znz-segment-z19/znz-train-z19-all-buffered/images-512/*')\n",
        "all_mask_files = glob.glob('znz-segment-z19/znz-train-z19-all-buffered/masks-512/*')\n",
        "print(len(all_img_files))\n",
        "print(len(all_mask_files))\n",
        "print(all_img_files[:10])\n",
        "print(all_mask_files[:10])\n",
        "\n",
        "#img = cv2.imread('trainx/X_img_144.bmp', cv2.IMREAD_COLOR)\n",
        "#img.shape\n",
        "\n",
        "#plt.imshow(img[:,:,::-1])\n",
        "\n",
        "img_files = glob.glob('znz-segment-z19/znz-train-z19-all-buffered/images-512/*')\n",
        "msk_files = glob.glob('znz-segment-z19/znz-train-z19-all-buffered/masks-512/*')\n",
        "\n",
        "img_files.sort()\n",
        "msk_files.sort()\n",
        "\n",
        "print(len(img_files))\n",
        "print(len(msk_files))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2691\n",
            "2691\n",
            "['znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_029_corrected_19_319460_270686_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_043_corrected_19_319455_270772_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_001_19_319384_270505_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_043_corrected_19_319461_270794_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_001_19_319366_270499_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_050_19_319442_270804_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_029_corrected_19_319452_270708_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_043_corrected_19_319457_270795_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_029_corrected_19_319443_270717_img.jpg', 'znz-segment-z19/znz-train-z19-all-buffered/images-512/grid_050_19_319469_270832_img.jpg']\n",
            "['znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_023_19_319443_270643_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_058_19_319441_270841_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_001_19_319370_270496_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_022_19_319423_270666_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_050_19_319439_270804_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_001_19_319390_270495_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_022_19_319433_270656_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_050_19_319442_270803_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_043_corrected_19_319454_270773_mask_buffered.png', 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/grid_023_19_319449_270670_mask_buffered.png']\n",
            "2691\n",
            "2691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pogHnNS59Io7",
        "outputId": "f6e6a73d-60f1-4c33-e6f5-5b3fbb4ba958"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for img_fl in tqdm(img_files):\n",
        "  #print(img_fl)\n",
        "  #break\n",
        "  img = cv2.imread('{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
        "  resized_img = cv2.resize(img,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  X.append(resized_img)\n",
        "  mask_name = 'znz-segment-z19/znz-train-z19-all-buffered/masks-512/'+str(img_fl.split('.')[0][:-4]).split('/')[-1]+\"_mask_buffered.png\"\n",
        "  #print(\"mn = \",mask_name)\n",
        "  #break\n",
        "  msk = cv2.imread('{}'.format(mask_name), cv2.IMREAD_GRAYSCALE)\n",
        "  resized_msk = cv2.resize(msk,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  Y.append(resized_msk)\n",
        "\n",
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2691/2691 [00:18<00:00, 145.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2691\n",
            "2691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcKyhcNz9Sm5",
        "outputId": "ec133ed0-91bd-4402-d28e-6effdcb7f3dc"
      },
      "source": [
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
        "\n",
        "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train = Y_train / 255\n",
        "Y_test = Y_test / 255\n",
        "\n",
        "Y_train = np.round(Y_train,0)\t\n",
        "Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2152, 256, 256, 3)\n",
            "(2152, 256, 256, 1)\n",
            "(539, 256, 256, 3)\n",
            "(539, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJfkGVv1-NUL"
      },
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "\n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "\n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def MultiResUnet(height, width, n_channels):\n",
        "    '''\n",
        "    MultiResUNet\n",
        "\n",
        "    Arguments:\n",
        "        height {int} -- height of image\n",
        "        width {int} -- width of image\n",
        "        n_channels {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKab8pcn-Rcl"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union\n",
        "\n",
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    fp = open('models/modelP_MultiResUNet_skinleison.json','w')\n",
        "    fp.write(model_json)\n",
        "    model.save_weights('models/modelW_MultiResUNet_skinleison.h5')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHBqEtnD9c_V"
      },
      "source": [
        "jaccard_index_list = []\n",
        "dice_coeff_list = []\n",
        "\n",
        "def evaluateModel(model, X_test, Y_test, batchSize):\n",
        "\n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i])\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))\n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "\n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))\n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "\n",
        "\n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "\n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "\n",
        "    jaccard_index_list.append(jacard)\n",
        "    dice_coeff_list.append(dice)\n",
        "    fp = open('models/log.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('models/best.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('models/best.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        saveModel(model)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSy57fp9c8P",
        "outputId": "2938eab8-2c95-4749-8fcf-73958133f9c1"
      },
      "source": [
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch : {}'.format(epoch+1))\n",
        "        history = model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)\n",
        "\n",
        "        # convert the history.history dict to a pandas DataFrame:\n",
        "        hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "        # save to json:\n",
        "        hist_json_file = 'history.json'\n",
        "        with open(hist_json_file, 'a') as out:\n",
        "            out.write(hist_df.to_json(f) + '\\n')\n",
        "\n",
        "        #with open(hist_json_file, mode='w') as f:\n",
        "        #    hist_df.to_json(f)\n",
        "\n",
        "        # or save to csv:\n",
        "        hist_csv_file = 'history.csv'\n",
        "        with open(hist_csv_file, 'a') as out:\n",
        "            out.write(hist_df.to_csv(f) + '\\n')\n",
        "\n",
        "\n",
        "        # with open(hist_csv_file, mode='w') as f:\n",
        "        #     hist_df.to_csv(f)\n",
        "\n",
        "        evaluateModel(model,X_test, Y_test,batchSize)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = MultiResUnet(height=256, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, Recall(), Precision() ,'accuracy'])\n",
        "\n",
        "saveModel(model)\n",
        "\n",
        "fp = open('models/log.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/best.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=150, batchSize=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1\n",
            " 643/1076 [================>.............] - ETA: 55s - loss: 0.5201 - dice_coef: 0.2267 - jacard: 0.1348 - recall: 0.6757 - precision: 0.4142 - accuracy: 0.8820"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKkFcfNC9c54"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtP6TNW49c28"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}